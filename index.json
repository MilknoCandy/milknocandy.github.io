[{"content":"1 Installation 1.1 Installation for python environment To install nvcc inside a Python virtual environment, conda is all you need. It lets you pick the exact CUDA version for each env, so you never clash with system-wide installs. Please follow the steps below to install nvcc:\nSearch for all available nvcc version 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # activate your conda environment first $ conda activate xxenv # search for available cudatoolkit versions $ conda search cudatoolkit --channel conda-forge # output like this: Loading channels: done # Name Version Build Channel cudatoolkit 5.5rc1 p0 anaconda/pkgs/pro cudatoolkit 5.5.1 p0 anaconda/pkgs/pro cudatoolkit 6.0 p0 anaconda/pkgs/pro cudatoolkit 7.0 1 anaconda/pkgs/pro cudatoolkit 7.5 0 anaconda/pkgs/free cudatoolkit 7.5 2 anaconda/pkgs/free cudatoolkit 8.0 1 anaconda/pkgs/free cudatoolkit 8.0 3 anaconda/pkgs/free cudatoolkit 9.0 h13b8566_0 anaconda/pkgs/main cudatoolkit 9.0 h13b8566_0 pkgs/main cudatoolkit 9.2 0 anaconda/pkgs/main cudatoolkit 9.2 0 pkgs/main ... Install specific version of nvcc If you install nvcc within the base environment, you may run into errors such as OSError: [Errno 39] Directory not empty: 'xxx/anaconda3/lib/ossl-modules'. Therefore, I recommend installing it in a manually created virtual environment instead. 1 2 # Install specific version of `nvcc` $ conda install -c nvidia cudatoolkit=11.8 -y # or conda install -c conda-forge cudatoolkit=x.x Now let us check what we have obtained by running this.\n1 2 3 4 5 6 $ conda list | grep cuda # output like this: cudatoolkit 11.8.0 h6a678d5_0 https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main nvidia-cuda-cupti-cu11 11.8.87 pypi_0 pypi nvidia-cuda-nvrtc-cu11 11.8.89 pypi_0 pypi nvidia-cuda-runtime-cu11 11.8.89 pypi_0 pypi Oops, it looks like the cuda-nvcc package is missing. Letâ€™s install it with conda.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ conda search cuda-nvcc --channel nvidia # output like this: Loading channels: done # Name Version Build Channel cuda-nvcc 11.5.50 h8f81028_0 nvidia cuda-nvcc 11.5.119 h2e31d95_0 nvidia cuda-nvcc 11.6.55 h5758ece_0 nvidia cuda-nvcc 11.6.112 hf7fc535_0 nvidia cuda-nvcc 11.6.124 hbba6d2d_0 nvidia cuda-nvcc 11.7.64 0 nvidia cuda-nvcc 11.7.99 0 nvidia cuda-nvcc 11.8.89 0 nvidia cuda-nvcc 12.0.76 0 nvidia ... # Install the corresponding version of nvcc $ conda install -c nvidia cuda-nvcc=11.8.89 -y Finally, let us check if nvcc is correctly installed.\n1 2 3 4 5 6 7 $ nvcc --version # output like this: nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0 Note that you may need to run the following command before checking nvcc.\n1 2 3 4 5 6 7 # set temporary variable to system environment variable export PATH=$CONDA_PREFIX/bin:$PATH export CUDA_HOME=$CONDA_PREFIX # or set this permanently echo \u0026#39;export PATH=/usr/local/cuda-12.1/bin:$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # refresh 2 Basic Usage Once nvcc is installed, you can start using it to compile your CUDA programs. Here are some basic commands to get you started:\nCompile a CUDA program 1 $ nvcc -o my_program my_program.cu This command compiles the my_program.cu file and generates an executable named my_program.\nCompile with specific architecture 1 $ nvcc -arch=sm_61 -o my_program my_program.cu This command compiles the CUDA program for a specific GPU architecture (in this case, sm_61).\n","permalink":"https://milknocandy.github.io/tech/2026-1-20-nvcc/","summary":"\u003ch2 id=\"1-installation\"\u003e1 Installation\u003c/h2\u003e\n\u003ch3 id=\"11-installation-for-python-environment\"\u003e1.1 Installation for python environment\u003c/h3\u003e\n\u003cp\u003eTo install \u003ccode\u003envcc\u003c/code\u003e inside a Python virtual environment, conda is all you need. It lets you pick the exact CUDA version for each env, so you never clash with system-wide installs. Please follow the steps below to install \u003ccode\u003envcc\u003c/code\u003e:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSearch for all available \u003ccode\u003envcc\u003c/code\u003e version\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\" id=\"hl-0-1\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-1\"\u003e 1\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-2\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-2\"\u003e 2\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-3\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-3\"\u003e 3\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-4\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-4\"\u003e 4\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-5\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-5\"\u003e 5\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-6\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-6\"\u003e 6\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-7\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-7\"\u003e 7\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-8\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-8\"\u003e 8\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-9\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-9\"\u003e 9\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-10\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-10\"\u003e10\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-11\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-11\"\u003e11\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-12\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-12\"\u003e12\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-13\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-13\"\u003e13\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-14\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-14\"\u003e14\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-15\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-15\"\u003e15\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-16\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-16\"\u003e16\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-17\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-17\"\u003e17\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-18\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-18\"\u003e18\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-19\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-19\"\u003e19\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-20\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-20\"\u003e20\u003c/a\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# activate your conda environment first\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ conda activate xxenv\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# search for available cudatoolkit versions\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ conda search cudatoolkit --channel conda-forge\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# output like this:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eLoading channels: \u003cspan class=\"k\"\u003edone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Name                       Version           Build  Channel             \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                   5.5rc1              p0  anaconda/pkgs/pro   \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                    5.5.1              p0  anaconda/pkgs/pro   \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      6.0              p0  anaconda/pkgs/pro   \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      7.0               \u003cspan class=\"m\"\u003e1\u003c/span\u003e  anaconda/pkgs/pro   \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      7.5               \u003cspan class=\"m\"\u003e0\u003c/span\u003e  anaconda/pkgs/free  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      7.5               \u003cspan class=\"m\"\u003e2\u003c/span\u003e  anaconda/pkgs/free  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      8.0               \u003cspan class=\"m\"\u003e1\u003c/span\u003e  anaconda/pkgs/free  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      8.0               \u003cspan class=\"m\"\u003e3\u003c/span\u003e  anaconda/pkgs/free  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      9.0      h13b8566_0  anaconda/pkgs/main  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      9.0      h13b8566_0  pkgs/main           \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      9.2               \u003cspan class=\"m\"\u003e0\u003c/span\u003e  anaconda/pkgs/main  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecudatoolkit                      9.2               \u003cspan class=\"m\"\u003e0\u003c/span\u003e  pkgs/main    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e...\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003col start=\"2\"\u003e\n\u003cli\u003eInstall specific version of \u003ccode\u003envcc\u003c/code\u003e\nIf you install nvcc within the base environment, you may run into errors such as \u003ccode\u003eOSError: [Errno 39] Directory not empty: 'xxx/anaconda3/lib/ossl-modules'\u003c/code\u003e. Therefore, I recommend installing it in a manually created virtual environment instead.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\" id=\"hl-1-1\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-1-1\"\u003e1\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-1-2\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-1-2\"\u003e2\u003c/a\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Install specific version of `nvcc`\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ conda install -c nvidia \u003cspan class=\"nv\"\u003ecudatoolkit\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e11.8 -y \u003cspan class=\"c1\"\u003e# or conda install -c conda-forge cudatoolkit=x.x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eNow let us check what we have obtained by running this.\u003c/p\u003e","title":"NVCC Master Guide: From Installation to Performance Tuning"},{"content":"1 Timeline Order Summarize the literature reviewed in chronological order.\n2023 ğŸ“ã€EMNLP 2023 - Mainã€‘- Sparse Low-rank Adaptation of Pre-trained Language Models (Tsinghua University, The University of Chicago)\nSubject: Adaptive Rank Selection\nProblem: Standard LoRA uses a fixed, inflexible rank (hyperparameter $ r\r$), requiring expensive manual tuning. Core Idea: Make the rank learnable rather than fixed. Mechanism: Gating: Introduces an optimizable gating unit to the low-rank matrices. Optimization: Uses proximal gradient methods to update the gates. Dynamics: Prunes less important ranks during training automatically. Result: Eliminates discrete rank search; the model discovers its own optimal rank structure. SoRA\r2024 ğŸ°ã€Arxiv 2024ã€‘- MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA-based Mixture of Experts (Sichuan University, Purdue University, Emory University, Nanyang Technology University)\nA solid summary of various LoRA variants.\rMixLoRA\rğŸ“”ã€ICLR 2024ã€‘- Mixture of LoRA Experts (Microsoft Research Asia, Tsinghua University) Subject: Multiple LoRA Merging\nProblem: Combining multiple LoRA adapters into a single model is challenging. Existing methods (e.g., linear interpolation or reference-tuning) either degrade the generation quality of pre-trained models or incur high training costs. Core Idea: Adaptively combine multiple LoRA adapters at each layer by gate function. Method: MoLE treats each trained layer of LoRA as an independent expert. It implements hierarchical weight control by embedding a learnable gating function in each layer, and dynamically learns the optimal combination weights by combining gating balance loss and domain-specific loss. Results: More flexible merging method for multiple LoRAs with negligible costs. Three LoRA composition strategies: (a) linear arithmetic, applying a single weight across all layers; (b) reference-tuning, retraining the large model with handcrafted masks that fuse multiple LoRA outputs; (c) MoLE, learning layer-wise distributions to set adaptive composition weights.\r2025 ğŸ°ã€Arxiv 2025ã€‘- ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation (University of California)\nNumerous efforts are devoted to reducing the trainable parameters of LoRA, but a significant reduction in parameters will lead to slower convergence, and an inadequate reduction method will also make the model prone to over-fitting. Moreover, many existing PEFT methods struggle to maintain cross-domain robustness after fine-tuning.\nObservation: LoRA\u0026rsquo;s A and B do not need to be uniquely configured across different layers to achieve optimal performance Method: Share matrix A or B across all layers while keeping the corresponding terms (e.g. qkv, out_proj) distinct in each layer. A variety of sharing strategies (share A, share B or share AB) are explored, with a key finding that such sharing does not compromise model performance. ShareLoRA: three sharing strategies (left) and ShareA applied across self-attention layers (right)\r","permalink":"https://milknocandy.github.io/posts/2026-01-16-lora/","summary":"\u003ch2 id=\"1-timeline-order\"\u003e1 Timeline Order\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSummarize the literature reviewed in chronological order.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ch3 id=\"2023\"\u003e2023\u003c/h3\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eğŸ“ã€\u003cem\u003e\u003cstrong\u003eEMNLP 2023 - Main\u003c/strong\u003e\u003c/em\u003eã€‘- Sparse Low-rank Adaptation of Pre-trained Language Models (\u003cem\u003eTsinghua University, The University of Chicago\u003c/em\u003e)\u003c/p\u003e\n\u003cdiv class=\"highlight-box default\"\u003e\r\n    \u003cdiv class=\"box-content\"\u003e\r\n        \u003cp\u003e\u003cstrong\u003eSubject:\u003c/strong\u003e Adaptive Rank Selection\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProblem:\u003c/strong\u003e Standard LoRA uses a fixed, inflexible rank (hyperparameter $ r\r\n $), requiring expensive manual tuning.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCore Idea:\u003c/strong\u003e Make the rank learnable rather than fixed.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMechanism:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGating:\u003c/strong\u003e Introduces an optimizable gating unit to the low-rank matrices.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOptimization:\u003c/strong\u003e Uses proximal gradient methods to update the gates.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDynamics:\u003c/strong\u003e Prunes less important ranks during training automatically.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eResult:\u003c/strong\u003e Eliminates discrete rank search; the model discovers its own optimal rank structure.\u003c/li\u003e\n\u003c/ul\u003e\r\n    \u003c/div\u003e\r\n\u003c/div\u003e\n\u003cp\u003e\r\n\u003cfigure \u003e\r\n    \u003cimg src=\"1-sora.png\" alt=\"SoRA\" /\u003e\u003cfigcaption\u003e\r\n        \u003cspan class=\"auto-fig-title\"\u003eSoRA\u003c/span\u003e\r\n    \u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e","title":"LoRA Variants Surveys"},{"content":" SparKï¼šDesigning Bert for Convolutional Networkss: Sparse and Hierarchical Masked Modeling (ICLR 2023 Spotlight)\nè®ºæ–‡ä»‹ç»ï¼šhttps://www.bilibili.com/video/BV11s4y1M7qL/\nBertç®—æ³•æ˜¯é®ä½æ•°æ®çš„ä¸€éƒ¨åˆ†ï¼Œç”¨æ¨¡å‹å»è¿›è¡Œé¢„æµ‹ï¼Œè¾¾åˆ°ä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ çš„æ•ˆæœã€‚è¿ç§»åˆ°å›¾åƒé¢†åŸŸä¸­çš„è§†è§‰Transformerçš„å·¥ä½œæ¯”å¦‚MAEï¼Œä½†æ˜¯ç›´æ¥å°†Transformeræ›¿æ¢ä¸ºå·ç§¯ç½‘ç»œåˆ™å‡ºç°é—®é¢˜ã€‚å¦‚ä¸‹å›¾ï¼Œzero-outingè¡¨ç¤ºç›´æ¥æ›¿æ¢ï¼š\nå¯ä»¥çœ‹åˆ°åªæœ‰0.1ä¸ªç‚¹çš„æå‡ï¼Œæ˜¯å®Œå…¨æ— æ•ˆçš„ã€‚ä¸‹é¢æ˜¯ä½œè€…çš„åˆ†æã€‚\nä¸ºä»€ä¹ˆå¤±è´¥ï¼Ÿ é—®é¢˜1ï¼šPixel Intensity Distribution Shift Transformeråœ¨å¤„ç†patchesæ—¶ï¼Œåªè¦ä¿è¯æ˜¯éšæœºåˆ å»ä¸€äº›patchesï¼Œå¯ä»¥ä¿è¯åˆ é™¤çš„patcheså’Œå›¾åƒçš„åƒç´ åˆ†å¸ƒæ˜¯ä¸€è‡´çš„ã€‚è€Œå·ç§¯ç¥ç»ç½‘ç»œåˆ™ä¸èƒ½åˆ å»ä¸€äº›åƒç´ ï¼Œåªèƒ½æ˜¯å°†ä¸€äº›åƒç´ â€œæ¶‚é»‘â€æ¥æ¨¡æ‹Ÿä¸¢å¤±è¿™éƒ¨åˆ†åƒç´ çš„ä¿¡æ¯ã€‚\nåƒç´ åˆ†å¸ƒã€‚æ¨ªè½´æ˜¯åƒç´ å¼ºåº¦ï¼Œçºµè½´æ˜¯åƒç´ å‡ºç°çš„é¢‘ç‡\ré—®é¢˜2ï¼šMask Patttern Vanishing å½“æˆ‘ä»¬åœ¨zero-outedçš„å›¾åƒä¸Šåšå·ç§¯ï¼Œå³è¿›è¡Œé®ç›–åçš„å›¾åƒï¼Œä¼šå‘ç°è¢«maskçš„åœ°æ–¹é€æ¸æ¶ˆå¤±äº†ï¼Œç±»ä¼¼å›¾å½¢å­¦æ“ä½œé‡Œçš„erosionæ•ˆæœã€‚\nåƒç´ æ¶ˆå¤±é—®é¢˜\ré—®é¢˜3ï¼ša gap between CV and NLP in data processing å·®å¼‚å¦‚ä¸‹ï¼š\nNLPä¸­ï¼Œæ•°æ®æ˜¯ç”±ä¸€ä¸ªä¸ªå•è¯ç»„æˆï¼Œæ¯ä¸ªå•è¯éƒ½æ˜¯ä¸€ä¸ªè¯­ä¹‰å•å…ƒï¼Œæœ‰å®ƒè‡ªå·±çš„å«ä¹‰ï¼Œå…·æœ‰ç¦»æ•£çš„ç‰¹ç‚¹ï¼›è€Œåœ¨CVä¸­ï¼Œæ•°æ®æ¥è‡ªé€šè¿‡ç…§ç›¸æœºè·å–åˆ°çš„æ¥è‡ªçœŸå®ä¸–ç•Œçš„å…‰å­¦ä¿¡æ¯ï¼Œå•ä¸ªåƒç´ å¹¶ä¸å­˜åœ¨æŸç§ä¿¡æ¯ï¼Œè¿ç»­çš„åƒç´ ç»„æˆçš„åƒç´ é›†åˆæ‰å¯ä»¥è¢«çœ‹åšè¯­ä¹‰å•å…ƒï¼Œå› æ­¤æ”¶é›†åˆ°çš„å…‰å­¦ä¿¡å·æ˜¯æ‹¥æœ‰è¿ç»­çš„ç‰¹ç‚¹ å›¾åƒä¸­çš„ç‰©ä½“æœ‰å¤§æœ‰å°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å¤šå°ºåº¦çš„å›¾åƒæ“ä½œã€‚è®¸å¤šç»å…¸çš„CVæ¨¡å‹éƒ½æ˜¯ä»å¤šä¸ªå°ºåº¦ï¼Œä½¿ç”¨å¤šå°ºåº¦å±‚æ¬¡åŒ–çš„ç»“æ„æ¥å¤„ç†å›¾åƒä¿¡æ¯ å› æ­¤NLPä¸­ï¼ŒåƒBertæ¨¡å‹åœ¨å¤„ç†æ•°æ®æ—¶éƒ½æ˜¯å•å°ºåº¦æ¦‚å¿µï¼Œä½†CVéƒ½æ˜¯å¤šå°ºåº¦çš„æ¦‚å¿µï¼Œè¿™é‡Œå°±æœ‰ä¸€ä¸ª gapï¼Œä¸èƒ½å¿½è§†è¿™ä¸ª gap è§£å†³æ–¹æ¡ˆ ä½¿ç”¨sparse Convolution è§£å†³é—®é¢˜1å’Œ2\nè¿™ä¿©é—®é¢˜çš„æ ¹æºéƒ½æ˜¯CNNsä¸èƒ½å¤„ç†ä¸è§„åˆ™ã€éšæœºmaskedçš„å›¾åƒï¼Œä½†æ˜¯ViTå¯ä»¥ã€‚\nç¨€ç–å·ç§¯ï¼ˆæƒ³æ³•æ¥è‡ª3Då·äº‘çš„ç‰¹ç‚¹ï¼‰å¯ä»¥è·³è¿‡æ‰€æœ‰â€œempty/masked/zeroâ€çš„ä½ç½®ï¼Œå› æ­¤ï¼š\nmaskedçš„ä½ç½®åœ¨ç¨€ç–å·ç§¯åä¸ä¼šå˜å°‘ï¼Œè§£å†³é—®é¢˜2 ä¸éœ€è¦â€œzero-out pixelsâ€æ¥æ¨¡æ‹Ÿä¸¢å¤±æ“ä½œï¼Œå³é®ç›–æ“ä½œï¼Œè§£å†³é—®é¢˜1 ä½¿ç”¨hierarchical encoder-decoder ä½œè€…ä½¿ç”¨å¤šå°ºåº¦çš„ç¼–ç è§£ç ç»“æ„æ¥åšBERTå¼è®­ç»ƒï¼Œå¦‚ä¸‹å›¾ï¼š\nç½‘ç»œç»“æ„\ræ€»ç»“å¦‚ä¸‹ï¼š\nä½œè€…çš„ç®—æ³•ä½œç”¨åœ¨4ä¸ªä¸åŒçš„å°ºåº¦ï¼ˆ4x/8x/16x/32xä¸‹é‡‡æ ·ï¼‰ æ¯ä¸ªç¨€ç–ç‰¹å¾$ S_i $å–‚ç»™decoderæ¥è·å¾—$ D_i $ï¼Œè¿™é‡Œç¨€ç–ç‰¹å¾ä¼šåšdesifyæ“ä½œï¼Œå³ç©ºçš„ä½ç½®å¡«å……masked token å’ŒUNetä¸€æ ·çš„è·³è¿æ¥ maskç™¾åˆ†ä¹‹å…­å å’ŒMAEä»¥åŠåŒæœŸçš„ConvNextV2çš„å¯¹æ¯”ï¼š\nå‡ ä¸ªç–‘ç‚¹ï¼š\nmaskç™¾åˆ†ä¹‹å…­åï¼Œæ¯”ä¾‹å…¶å®æ˜¯æ¯”è¾ƒé«˜çš„ï¼ŒåŸMAEé‡Œä¹Ÿæ˜¯75%ï¼Œä¹Ÿæ˜¯éå¸¸é«˜çš„ï¼Œä½œè€…çŒœæµ‹å›¾åƒé‡Œçš„å†—ä½™é‡æ¯”NLPé‡Œçš„å†—ä½™é‡è¦é«˜å¾ˆå¤š maskçš„åœ°æ–¹æ›¿æ¢ä¸ºmask tokenæ—¶è®­ç»ƒå‘ç°lossä¼šå˜æˆnanï¼Œè¿™ä¸ªé—®é¢˜å¾ˆå…³é”®ï¼Œæ˜¯å¦è¯´æ˜å·ç§¯è¿™ç§å±€éƒ¨ä¿¡æ¯æ— æ³•å¾ˆå¥½çš„æä¾›é‡å»ºæ‰€éœ€è¦çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´é‡å»ºçš„tokenæ²¡æœ‰ä¸€ä¸ªæ˜ç¡®çš„è¿˜åŸæ–¹å‘ï¼Œæ¯•ç«Ÿå±€éƒ¨æ„Ÿå—é‡é™¤éæ˜¯èƒ½å¤Ÿåˆšå¥½è¦†ç›–åˆ°ç›®æ ‡è¢«maskç‰©ä½“ï¼Œå¦åˆ™åªæ˜¯ä¸€å †åƒç´ å—ã€‚è€Œmask tokenç›¸å½“äºå¼•å…¥å™ªå£°äº†ï¼ŒSparkè¿™ç§ç¨€ç–å·ç§¯çš„æ“ä½œåˆ™æ˜¯å¯ä»¥é¿å…è¢«maskéƒ¨åˆ†çš„å½±å“ã€‚ ","permalink":"https://milknocandy.github.io/posts/2025-08-28-spark/","summary":"\u003cblockquote\u003e\n\u003cp\u003eSparKï¼š\u003ca href=\"https://github.com/keyu-tian/SparK\"\u003eDesigning Bert for Convolutional Networkss: Sparse and Hierarchical Masked Modeling\u003c/a\u003e (ICLR 2023 Spotlight)\u003c/p\u003e\n\u003cp\u003eè®ºæ–‡ä»‹ç»ï¼š\u003cfont style=\"color:rgb(38, 38, 38);\"\u003e\u003c/font\u003e\u003ca href=\"https://www.bilibili.com/video/BV11s4y1M7qL/\"\u003ehttps://www.bilibili.com/video/BV11s4y1M7qL/\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBertç®—æ³•æ˜¯é®ä½æ•°æ®çš„ä¸€éƒ¨åˆ†ï¼Œç”¨æ¨¡å‹å»è¿›è¡Œé¢„æµ‹ï¼Œè¾¾åˆ°ä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ çš„æ•ˆæœã€‚è¿ç§»åˆ°å›¾åƒé¢†åŸŸä¸­çš„è§†è§‰Transformerçš„å·¥ä½œæ¯”å¦‚MAEï¼Œä½†æ˜¯ç›´æ¥å°†Transformeræ›¿æ¢ä¸ºå·ç§¯ç½‘ç»œåˆ™å‡ºç°é—®é¢˜ã€‚å¦‚ä¸‹å›¾ï¼Œzero-outingè¡¨ç¤ºç›´æ¥æ›¿æ¢ï¼š\u003c/p\u003e\n\u003c!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼šHIERARCHY APE MASKING EPOCH METHOD STD. LOSS ACC. 83.1 -1.0 NOT PRETRAINED 0.07 SPARK(OURS) 84.1 2 0.0 MASKED ONLY 1600 SPARSE X 3 83.2 0.06 ZERO-OUTING 1600 -0.9 MASKED ONLY ZERO-OUTING --\u003e\r\n\u003cp\u003e\r\n\u003cfigure \u003e\r\n    \u003cimg src=\"fig1.png\" alt=\"\" /\u003e\u003c/figure\u003e\u003c/p\u003e\n\u003cp\u003eå¯ä»¥çœ‹åˆ°åªæœ‰0.1ä¸ªç‚¹çš„æå‡ï¼Œæ˜¯å®Œå…¨æ— æ•ˆçš„ã€‚ä¸‹é¢æ˜¯ä½œè€…çš„åˆ†æã€‚\u003c/p\u003e\n\u003ch2 id=\"ä¸ºä»€ä¹ˆå¤±è´¥\"\u003eä¸ºä»€ä¹ˆå¤±è´¥ï¼Ÿ\u003c/h2\u003e\n\u003ch3 id=\"é—®é¢˜1pixel-intensity-distribution-shift\"\u003eé—®é¢˜1ï¼šPixel Intensity Distribution Shift\u003c/h3\u003e\n\u003cp\u003eTransformeråœ¨å¤„ç†patchesæ—¶ï¼Œåªè¦ä¿è¯æ˜¯éšæœºåˆ å»ä¸€äº›patchesï¼Œå¯ä»¥ä¿è¯åˆ é™¤çš„patcheså’Œå›¾åƒçš„åƒç´ åˆ†å¸ƒæ˜¯ä¸€è‡´çš„ã€‚è€Œå·ç§¯ç¥ç»ç½‘ç»œåˆ™ä¸èƒ½åˆ å»ä¸€äº›åƒç´ ï¼Œåªèƒ½æ˜¯å°†ä¸€äº›åƒç´ â€œæ¶‚é»‘â€æ¥æ¨¡æ‹Ÿä¸¢å¤±è¿™éƒ¨åˆ†åƒç´ çš„ä¿¡æ¯ã€‚\u003c/p\u003e\n\u003c!-- è¿™æ˜¯ä¸€å¼ å›¾ç‰‡ï¼Œocr å†…å®¹ä¸ºï¼šCNN SPARSE CNN TRANSFORMER ENCODING PROCESS: PIXEL INTENSITY DATA DISTRIBUTION MA PROBABILITY BEFORE/AFTER MASKING: (A)DIRECTLY DROPPING (C)SPARSELY DROPPING (B)ZERO-OUTING (D) RAW INPUT --\u003e\r\n\u003cp\u003e\r\n\u003cfigure \u003e\r\n    \u003cimg src=\"fig2.png\" alt=\"åƒç´ åˆ†å¸ƒã€‚æ¨ªè½´æ˜¯åƒç´ å¼ºåº¦ï¼Œçºµè½´æ˜¯åƒç´ å‡ºç°çš„é¢‘ç‡\" /\u003e\u003cfigcaption\u003e\r\n        \u003cspan class=\"auto-fig-title\"\u003eåƒç´ åˆ†å¸ƒã€‚æ¨ªè½´æ˜¯åƒç´ å¼ºåº¦ï¼Œçºµè½´æ˜¯åƒç´ å‡ºç°çš„é¢‘ç‡\u003c/span\u003e\r\n    \u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e","title":"â€‹Designing Bert for Convolutional Networks"},{"content":" æ¥æºï¼šNIPS 2023\nè®ºæ–‡åœ°å€ï¼šhttp://arxiv.org/abs/2310.06907\nä»£ç åœ°å€ï¼šâŒ\nä½œè€…ä¸»é¡µï¼šäºŒä½œè°¢ä¼Ÿè¿ªä¸»é¡µhttps://weidixie.github.io/\né¡¹ç›®ä¸»é¡µï¼šhttps://kuis-ai.github.io/solv/\nä»‹ç» èƒŒæ™¯ï¼šæ— ç›‘ç£å¤šç›®æ ‡åˆ†å‰²å€ŸåŠ©è‡ªç›‘ç£å­¦ä¹ é¢„è®­ç»ƒä¸­å­¦ä¹ åˆ°çš„å¼ºåŠ›çš„è¯­ä¹‰ä¿¡æ¯å±•ç¤ºäº†æ˜¾è‘—çš„æ•ˆæœã€‚é€šå¸¸ä¹Ÿæ˜¯é€šè¿‡æ·»åŠ é¢å¤–çš„æ¨¡æ€ï¼ˆæ¯”å¦‚æ·±åº¦ã€åŠ¨ä½œï¼‰æ¥å¢å¼ºè§†é¢‘åºåˆ—çš„åˆ†å‰²ç»“æœã€‚ç„¶è€Œï¼Œåœ¨ _åˆæˆåºåˆ— _ä¸­è§‚å¯Ÿåˆ°çš„æ€§èƒ½æå‡ä¾èµ–äºé¢å¤–ä¿¡æ¯çš„é²æ£’æ€§ï¼Œå¹¶ä¸èƒ½è½¬åŒ–ä¸ºæ›´å…·æŒ‘æˆ˜çš„çœŸå®ä¸–ç•Œåœºæ™¯ã€‚\nä»»åŠ¡ï¼šç»™å®šä¸€ä¸ªå¤æ‚åœºæ™¯çš„è§†é¢‘åºåˆ—ï¼Œç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªè§†è§‰ç³»ç»Ÿèƒ½å¤Ÿå‘ç°ã€è¿½è¸ªå’Œåˆ†å‰²å›¾åƒå¸§é‡Œçš„ç›®æ ‡ï¼Œå°†æ•°ç™¾ä¸‡çš„åƒç´ çš„è§†è§‰ä¿¡æ¯æŠ½è±¡ä¸ºè¯­ä¹‰éƒ¨åˆ†ã€‚ï¼ˆobject-centricè§†è§‰è¡¨å¾å­¦ä¹ ï¼‰\n(a) Ground Truth\n(b) Prediction\né¢†åŸŸçš„å‘å±•ï¼šä»åˆæˆå›¾åƒå¼€å§‹ï¼Œè½¬å‘in-the-wildå›¾åƒå’Œreal-worldè§†é¢‘ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨è‡ªç¼–ç å™¨è®­ç»ƒèŒƒå¼ï¼ˆå¦‚é‡å»ºè¾“å…¥ä¿¡å·ï¼Œå¸Œæœ›èƒ½åŸºäºæ•°æ®æˆ–ç»“æ„çš„å…ˆéªŒæ¥å°†åŒºåŸŸåƒç´ åˆ†ç»„ä¸ºæœ‰è¯­ä¹‰æ„ä¹‰çš„å¯¹è±¡ï¼‰ã€‚\nå¯¹å›¾åƒï¼šä½¿ç”¨æ¥æºäºé¢„è®­ç»ƒæ¨¡å‹çš„ä½çº§ç‰¹å¾ï¼ˆå¦‚é¢œè‰²ã€è¯­ä¹‰ç‰¹å¾ç­‰ï¼‰æ¥ç¡®å®šåƒç´ åˆ°ç›®æ ‡çš„åˆ†é… å¯¹è§†é¢‘ï¼šé€šå¸¸ç»“åˆé¢å¤–çš„æ¨¡æ€ã€ä¿¡å·ï¼ˆå¦‚å…‰æµã€æ·±åº¦å›¾ï¼‰ï¼Œå¯ç›´æ¥ä»ä¸è¿ç»­æ€§è·å¾—åˆ†å‰²æ©ç  æå‡ºé—®é¢˜ ä½¿ç”¨é¢å¤–ä¿¡æ¯å¸¦æ¥çš„é—®é¢˜ï¼šåœ¨è§†é¢‘ä¸­ä½¿ç”¨é¢å¤–çš„ä¿¡å·ä¼šå¢åŠ è®¡ç®—å¼€é”€å’Œè¯¯å·®ç´¯ç§¯ã€‚æ¯”å¦‚å…‰æµä¿¡å·åœ¨å¤„ç†é™æ€æˆ–å¯å˜å½¢ç‰©ä½“ä»¥åŠå¸§é—´å¤§ä½ç§»æ—¶å¯èƒ½ä¼šäº§ç”Ÿé—®é¢˜ï¼Œè€Œæ·±åº¦å€¼åœ¨æ™®é€šè§†é¢‘ä¸­å¯èƒ½ä¸æ˜“è·å¾—ï¼Œåœ¨ä½å…‰ç…§æˆ–ä½å¯¹æ¯”åº¦ç¯å¢ƒä¸­å…¶ä¼°ç®—ä¹Ÿä¼šå—åˆ°å½±å“ã€‚\nè¿‡åº¦åˆ†å‰²é—®é¢˜ï¼šç”±äºè§†è§‰åœºæ™¯çš„å¤æ‚æ€§ï¼Œä½¿ç”¨å›ºå®šæ•°é‡çš„slotså¯èƒ½å¯¼è‡´è¿‡åº¦åˆ†å‰²é—®é¢˜ï¼ˆover-segmentation issuseï¼‰ã€‚\nè§£å†³é—®é¢˜ ä½œè€…æ–¹æ³•ï¼šé¦–æ¬¡æå‡ºç”¨äºçœŸå®ä¸–ç•Œåºåˆ—ä¸­å¤šç›®æ ‡åˆ†å‰²çš„å®Œå…¨æ— ç›‘ç£æ–¹æ³•ã€‚SOLVï¼Œä¸€ä¸ªèƒ½å¤Ÿå‘ç°çœŸå®ä¸–ç•Œè§†é¢‘åºåˆ—ä¸­å¤šä¸ªç›®æ ‡ä¸”ä¸ä½¿ç”¨é¢å¤–çš„æ¨¡æ€ä¿¡æ¯æˆ–ä»»ä½•ç±»ä¼¼å¼±ç›‘ç£æ–¹æ³•ï¼ˆæ¯”å¦‚ä½¿ç”¨ç¬¬ä¸€å¸§è¿›è¡Œåˆå§‹åŒ–ï¼‰ã€‚\næ–¹æ¡ˆï¼šä½¿ç”¨è½´å‘ç©ºé—´-æ—¶éš™æ³¨æ„åŠ›ï¼ˆaxial spatial-temporal slot attentionsï¼‰\né¦–å…ˆå¯¹æ¯å¸§å†…ç©ºé—´åŒºåŸŸè¿›è¡Œåˆ†ç»„ ç„¶åä½¿ç”¨æ¥è‡ªç›¸é‚»å¸§çš„äº¤äº’æ¥ä¸°å¯Œæ—¶éš™è¡¨ç¤ºï¼ˆslot representationsï¼‰ è®­ç»ƒç­–ç•¥ï¼šmasked autoencoderï¼ˆMAEï¼‰è®­ç»ƒèŒƒå¼ã€‚ä¸¤ä¸ªä¼˜åŠ¿ï¼š\nå……å½“ä¿¡æ¯ç“¶é¢ˆï¼ˆinformation bottleneckï¼‰ï¼Œè®©æ¨¡å‹è§‚å¯Ÿéƒ¨åˆ†åŒºåŸŸï¼Œå¼ºè¿«æ¨¡å‹å­¦ä¹ é«˜çº§è¯­ä¹‰ç»“æ„ã€‚ ç¼“è§£å†…å­˜é™åˆ¶ï¼Œæœ‰åŠ©äºæé«˜è®¡ç®—æ•ˆç‡ é’ˆå¯¹over-segmentationé—®é¢˜ï¼šä½œè€…é€šè¿‡ä½¿ç”¨ç®€å•çš„èšç±»ç®—æ³•æ¥èåˆç›¸ä¼¼çš„slotsã€‚\næ€»çš„æ¥è¯´ï¼Œè´¡çŒ®å¦‚ä¸‹ï¼š\næå‡ºä¸€ä¸ªåœ¨çœŸå®ä¸–ç•Œè§†é¢‘ä¸Šçš„è‡ªç›‘ç£å¤šç›®æ ‡åˆ†å‰²æ¨¡å‹ï¼Œä½¿ç”¨axial spatial-temporal slots attentionï¼Œèƒ½æœ‰æ•ˆåœ°å°†å…·æœ‰ç›¸ä¼¼ç‰¹æ€§çš„è§†è§‰åŒºåŸŸè¿›è¡Œåˆ†ç»„ï¼Œè€Œä¸éœ€è¦ä½¿ç”¨é¢å¤–çš„ä¿¡å·ã€‚ å±•ç¤ºäº†ä¸€ä¸ªåŸºäºæ©ç ç‰¹å¾é‡å»ºçš„object-centricå­¦ä¹ æ–¹å¼ä»¥åŠslotèåˆæ–¹æ³•ã€‚ MOVi-Eå’ŒYoutube-VIS 2019æ•°æ®é›†ä¸Šçš„SOTAä»¥åŠDAVIS2017æ•°æ®é›†ä¸Šçš„å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ slotå³è§†é¢‘ä¸­çš„å„ç‰©ä½“å¯¹è±¡ï¼Œè§ä¸‹å›¾ã€‚\nSource from: Conditional object-centric learning from video\rç›¸å…³å·¥ä½œ Object-centric Learning å›¾åƒå’Œè§†é¢‘çš„object-centricæ— ç›‘ç£è¡¨å¾å­¦ä¹ ç°æœ‰å‡ ç§è§£å†³åŠæ³•ï¼š\nå¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼š Object discovery and representation networks.ï¼ˆECCV2022ï¼‰ Contrastive learning of structured world models.ï¼ˆICLR2020ï¼‰ Groupvit: Semantic segmentation emerges from text supervision.ï¼ˆCVPR2022ï¼‰ é‡å»ºç›®æ ‡æ–¹æ³•ï¼ˆå°†è¾“å…¥åˆ‡åˆ†ä¹˜æ½œåœ¨ç©ºé—´ä¸­çš„ä¸€ç»„åŒºåŸŸè¾¨è¯†å˜é‡ï¼Œå³slotsï¼Œç„¶åå°†å…¶å’Œå¯¹è±¡çš„ä¸åŒå¯¹è±¡è¿›è¡Œç»‘å®šï¼‰ï¼š åº”ç”¨äºå›¾åƒï¼š Multi-object representation learning with iterative variational inference.ï¼ˆICML2019ï¼‰ Monet: Unsupervised scene decomposition and representation. Spatially invariant unsupervised object detection with convolutional neural networks.ï¼ˆAAAI2019ï¼‰ Generative scene graph networks.ï¼ˆICLR2021ï¼‰ Genesis: Generative scene inference and sampling with object-centric latent representations.ï¼ˆICLR2020ï¼‰ Space: Unsupervised object-oriented scene representation via spatial attention and decomposition.ï¼ˆICLR2020ï¼‰ Unsupervised foreground extraction via deep region competition.ï¼ˆNIPS2021ï¼‰ Attend, infer, repeat: Fast scene understanding with generative modelsï¼ˆNIPS2016ï¼‰ Tagger: Deep unsupervised perceptual grouping.ï¼ˆNIPS2016ï¼‰ Unsupervised learning of compositional energy concepts.ï¼ˆNIPS2021ï¼‰ Object-centric learning with slot attention.ï¼ˆNIPS2020ï¼‰ Illiterate dall-e learns to compose.ï¼ˆICLR2022ï¼‰ åº”ç”¨äºè§†é¢‘ï¼š Simone: View-invariant, temporally-abstracted object representations via unsupervised video decomposition.ï¼ˆNIPS2021ï¼‰ Faster attend-infer-repeat with tractable probabilistic models.ï¼ˆICLR2019ï¼‰ Neural expectation maximization.ï¼ˆNIPS2017ï¼‰ Conditional object-centric learning from video.ï¼ˆICLR2022ï¼‰ Scalor: Generative world models with scalable object representations.ï¼ˆICLR2020ï¼‰ Entity abstraction in visual model-based reinforcement learning.ï¼ˆCoRL2020ï¼‰ Parts: Unsupervised segmentation with slots, attention and independence maximization.ğŸ¤”ï¼ˆICCV2021ï¼‰ Sequential attend, infer, repeat: Generative modelling of moving objects.ï¼ˆNIPS2018ï¼‰ è¿™äº›æ–¹æ³•éƒ½æ˜¯åœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡ŒéªŒè¯çš„ï¼Œä¸”ç”±äºå¤æ‚æ€§çš„å¢åŠ ï¼Œå¾ˆéš¾æ¨å¹¿åˆ°ç°å®ä¸–ç•Œçš„åœºæ™¯ä¸­ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¹‹å‰çš„ç ”ç©¶è€…ä»¬è€ƒè™‘æ¢ç´¢é¢å¤–çš„ä¿¡æ¯å¼•å¯¼ï¼š\nåŸºäº3Dç»“æ„ï¼š Roots: Object-centric representation and rendering of 3d scenes.ï¼ˆJMLR2021ï¼‰ Giraffe: Representing scenes as compositional generative neural feature fields.ï¼ˆCVPR2021ï¼‰ Unsupervised object-centric video generation and decomposition in 3d.ï¼ˆNIPS2020ï¼‰ åŸºäºä¸åŒæ¨¡æ€ä¿¡æ¯çš„é‡å»ºï¼š å…‰æµï¼šConditional object-centric learning from video.ï¼ˆICLR2022ï¼‰ æ·±åº¦ï¼šSavi++: Towards end-to-end object-centric learning from real-world videos.ï¼ˆNIPS2022ï¼‰ å½“å‰ï¼Œåœ¨æ²¡æœ‰ç²¾ç¡®å¼•å¯¼çš„æƒ…å†µä¸‹å‡†ç¡®è¯†åˆ«å¤æ‚è§†è§‰åœºæ™¯ä¸­çš„ç‰©ä½“ä»å…·æœ‰æŒ‘æˆ˜ã€‚ç°æœ‰å·¥ä½œä»¥æ¥äºä»è¿åŠ¨åˆ†å‰²æ©ç [R1-2]æˆ–åˆå§‹å¯¹è±¡ä½ç½®[R3-4]çš„å¼•å¯¼åˆå§‹åŒ–ã€‚ä¸ºå…‹æœè¿™ä¸ªå±€é™ï¼ŒDINOSAUR[R6]å€ŸåŠ©ä¹‹å‰çš„é¢„è®­ç»ƒæ¨¡å‹[R5]å­¦ä¹ åˆ°çš„å½’çº³åç½®æ¥é‡å»ºç‰¹å¾ç©ºé—´ã€‚ä½œè€…ä¹Ÿæ˜¯è¿™ä¸ªæ–¹æ³•æ¥åœ¨çœŸå®æ•°æ®ä¸­å­¦ä¹ object-centricè¡¨å¾ï¼Œæ— éœ€ä»»ä½•å¼•å¯¼åˆå§‹åŒ–æˆ–æ˜æ˜¾çš„ç›‘ç£ä¿¡å·ã€‚\nObject Localizaiton from DINO Features DINOå±•ç¤ºäº†VITåœ¨è‡ªç›‘ç£å­¦ä¹ ä¸­è¶…å¼ºçš„æ€§èƒ½ã€‚ä¸€äº›ç ”ç©¶è€…[R7]é€šè¿‡èšç±»ç­‰ä¼ ç»Ÿçš„å›¾åˆ’åˆ†æ–¹æ³•å°†DINOæå–åˆ°çš„ç‰¹å¾è¿›è¡Œåˆ†ç»„ï¼Œåº”ç”¨åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ã€‚CutLERå°†è¿™ä¸ªæ–¹æ³•è¿›è¡Œäº†æ‰©å±•ï¼Œæå‡ºäº†MaskCutå¯ä»¥ä¸æ–­çš„ç”Ÿæˆä¼ªæ ‡ç­¾å¹¶æ›´æ–°ï¼Œå€Ÿæ­¤è®­ç»ƒç½‘ç»œã€‚\nPipeline of CutLER\rObservations from Deep Spectral Methods[R7]\rDeep Spectral Methods\rVideo Object Segmentation Video Object Segmentation(VOS)æ—¨åœ¨è¯†åˆ«è§†é¢‘ä¸­æ˜¾è‘—çš„å¯¹è±¡ï¼š\næ— ç›‘ç£è®¾ç½®ä¸‹ï¼Œä¸ä¾èµ–æ ‡æ³¨ï¼Œ åŠç›‘ç£è®¾ç½®ä¸‹çš„è¯„ä¼°ä»…æ ‡æ³¨ç¬¬ä¸€å¸§ã€‚ æ¨ç†è¿‡ç¨‹æ˜¯æ— ç›‘ç£çš„ï¼Œä½†æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­ä»è¦ç”¨åˆ°æ ‡æ³¨æ•°æ®ã€‚Relying on labelled data during training might introduce a bias towards the labelled set of classes that is available during training.ä½¿ç”¨æ ‡è®°æ•°æ®ä¼šå¯¼è‡´æ¨¡å‹è®­ç»ƒäº§ç”Ÿåç½®æ•ˆæœï¼Œå³åå‘è®­ç»ƒæ•°æ®ä¸­çš„å·²æ ‡è®°ç±»åˆ«å¯¹è±¡ã€‚\nåŠ¨ä½œä¿¡æ¯é€šå¸¸åœ¨æ— ç›‘ç£VOSä¸­ç”¨äºè·¨æ—¶é—´åŒ¹é…å¯¹è±¡åŒºåŸŸã€‚åœ¨ç”¨objecti-centricæ–¹æ³•è¿›è¡Œå¤šå®ä¾‹å¯¹è±¡åˆ†ç¦»æ—¶ï¼ŒåŠ¨ä½œä¿¡æ¯å°¤ä¸ºæ–¹ä¾¿ã€‚Motion Groupingå­¦ä¹ object-centricè¡¨å¾ï¼Œé€šè¿‡å¯¹æµä¸­çš„patternsè¿›è¡Œåˆ†ç»„æ¥åˆ†å‰²è¿åŠ¨å¯¹è±¡ã€‚æœ€è¿‘çš„å·¥ä½œä¸»è¦å€ŸåŠ©åºåˆ—æ¨¡å‹ï¼Œå¼•å…¥é¢å¤–çš„ä¿¡æ¯ã€‚æœ¬å·¥ä½œä¸­ï¼Œä½œè€…ä»å¤šä¸ªå¸§ä¸­å­¦ä¹ temporal slotæ—¶éš™è¡¨å¾ï¼Œä¸ä½¿ç”¨ä»»ä½•æ˜¾å¼çš„è¿åŠ¨ä¿¡æ¯ã€‚è¿™æ ·å¯ä»¥é¿å…åœ¨æ— æ³•å¯é åœ°ä¼°è®¡flowæ—¶å¯¼è‡´çš„æ€§èƒ½ä¸‹é™ã€‚\n[R1]: Discovering objects that can move.ï¼ˆCVPR2022ï¼‰\n[R2]: Object discovery from motion-guided tokens.ï¼ˆCVPR2023ï¼‰\n[R3]: Savi++: Towards end-to-end object-centric learning from real-world videos.ï¼ˆNIPS2022ï¼‰\n[R4]: Conditional object-centric learning from video.ï¼ˆICLR2022ï¼‰\n[R5]: Emerging properties in self-supervised vision transformers.ï¼ˆICCV2021ï¼‰\n[R6]: Bridging the gap to real-world object-centric learning.ï¼ˆICLR2023ï¼‰\n[R7]: Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization.ï¼ˆCVPR2022ï¼‰\næ–¹æ³• é¦–å…ˆä»‹ç»è€ƒè™‘åˆ°çš„åœºæ™¯é—®é¢˜ï¼Œç„¶åæè¿°æå‡ºçš„object-centricç»“æ„ç»†èŠ‚ã€‚\nProblem Scenario è¾“å…¥ï¼šç»™å®šä¸€ä¸ªRGBè§†é¢‘ç‰‡æ®µä½œä¸ºè¾“å…¥ï¼Œæ¯”å¦‚$ \\mathcal{V}_t=\\{\\rm{v_{t-n}},\\cdots,v_t, \\cdots, v_{t+n}\\}\\in\\mathbb R^{(2n+1)\\times H\\times W\\times 3} $\næˆ‘ä»¬çš„ç›®æ ‡ï¼šè®­ç»ƒä¸€ä¸ªobject-centricæ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†è¿™ä¸ªç‰‡æ®µï¼Œè¾“å‡ºæ‰€æœ‰å¯¹è±¡å®ä¾‹çš„åˆ†å‰²æ©ç ï¼Œæ¯”å¦‚å‘ç°å¹¶è¿½è¸ªè§†é¢‘ä¸­çš„å®ä¾‹\nå€ŸåŠ©è‡ªç›‘ç£å­¦ä¹ ï¼Œæˆ‘ä»¬å°†è¯¥é—®é¢˜ç”¨å…¬å¼æ¥æè¿°ä¸ºï¼š\n$$ m_t=\\Phi(\\mathcal V_t;\\Theta)=\\Phi_{vis-dec}\\circ\\Phi_{st-bind}\\circ\\Phi_{vis-enc}(\\mathcal V_t)\\tag{1} $$è¿™é‡Œ$ m_t\\in\\mathbb R^{K_t\\times H\\times W} $è¡¨ç¤ºä¸­é—´å¸§çš„è¾“å‡ºåˆ†å‰²æ©ç ï¼Œ$ K_t $æ˜¯è¢«è®¤ä¸ºæ˜¯å¯¹è±¡çš„æ•°é‡ã€‚å¯¹æ¯å¸§è¿›è¡Œåˆ†å‰²åï¼Œå†ä½¿ç”¨Hungarian matchingæ¥è¿½è¸ªè§†é¢‘ä¸­çš„è·¨å¸§å¯¹è±¡ã€‚$ \\Phi(\\cdot;\\Theta) $æ˜¯æå‡ºçš„åˆ†å‰²æ¨¡å‹ï¼Œç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼š\nvisual encoderè§†è§‰ç¼–ç å™¨ - ç”¨äºé€å¸§æå–è§†è§‰ç‰¹å¾ spatial-temporal axial binding - é¦–å…ˆå°†åƒç´ åˆ†ç»„åˆ°å¸§å†…çš„slotsä¸­ï¼Œç„¶åè·¨æ—¶é—´å¸§æ¥è¿æ¥è¿™äº›slots visual decoderè§†è§‰è§£ç å™¨ - é€šè¿‡å¯¹spatial-temporal slotsè¿›è¡Œè§£ç ï¼Œé‡å»ºå¯†é›†çš„è§†è§‰ç‰¹å¾ï¼Œå‰¯äº§å“ä¸ºç›®æ ‡çš„åˆ†å‰²æ©ç  ç»“æ„å‰–æ ä½œè€…æå‡ºçš„ç»“æ„æ˜¯Transformerçš„å˜ä½“ï¼Œè®­ç»ƒæ–¹å¼å’Œç®€å•çš„masked autoencoderä¸€è‡´ï¼Œæ¯”å¦‚æ ¹æ®ç»™å®šçš„éƒ¨åˆ†è¾“å…¥è§‚å¯Ÿæ¥é‡å»ºå®Œæ•´çš„ä¿¡å·ã€‚å’Œæ ‡å‡†çš„MAEä¸åŒçš„æ˜¯ï¼ŒMAEåœ¨åƒç´ ç©ºé—´é‡å»ºå›¾åƒï¼Œä½œè€…çš„åˆ™æ˜¯ä¸€ä¸ªä¿¡æ¯ç“¶é¢ˆè®¾è®¡information bottleneck designï¼š\né¦–å…ˆå°†spatial-temporalç‰¹å¾åˆ†é…åˆ°slotsä¸­ ç„¶åä»æ½œåœ¨slotsä¸­é‡å»ºå¯†é›†è§†è§‰ç‰¹å¾ ç”±æ­¤ï¼Œæ¯ä¸ªslotéƒ½è¢«é™„åŠ åˆ°ä¸€ä¸ªè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„å¯¹è±¡ä¸Šï¼Œä¸”å¯é€šè¿‡é‡å»ºè¿‡ç¨‹è·å¾—åˆ†å‰²æ©ç ï¼ˆå‰¯äº§å“ï¼‰ï¼Œä¸ä¾èµ–æ‰‹å·¥æ ‡æ³¨çš„æ ‡ç­¾ã€‚\nVisual Encoder å’Œæ ‡å‡†çš„VITä¸€æ ·ï¼Œå¯¹è¾“å…¥çš„RGBè§†é¢‘ç‰‡æ®µï¼Œæˆ‘ä»¬å°†æ¯å¼ å›¾åƒåˆ‡åˆ†ä¸ºä¸é‡å çš„patchesï¼Œå¾—åˆ°$ \\mathcal V_t=\\{v_{t-n},\\cdots,v_t,\\cdots,v_{t+n}\\}\\in\\mathbb R^{(2n+1)\\times N\\times(3P^2)} $ï¼Œè¿™é‡Œçš„$ N=HW/P^2 $è¡¨ç¤ºç”¨å°ºå¯¸ä¸º$ P $çš„patchæ¥å¯¹æ¯å¸§æå–åˆ°çš„tokensçš„æ•°é‡ã€‚Visual Encoderæœ‰token dropå’Œç‰¹å¾æå–ç»„æˆã€‚\nToken Dropï¼šä½œä¸ºencoderçš„è¾“å…¥ï¼Œæˆ‘ä»¬åªé‡‡æ ·patchesçš„éƒ¨åˆ†å­é›†ã€‚é‡‡æ ·ç­–ç•¥éå¸¸ç›´æ¥ï¼šéšæœºä¸¢å¼ƒæ¯å¸§å›ºå®šæ¯”ç‡çš„è¾“å…¥patchesï¼Œè¿™é‡Œ$ N' $å³éšæœºé‡‡æ ·åå¾—åˆ°çš„tokensæ•°é‡ï¼š\n$$\r\\begin{align}\r\\mathcal V_t\u0026=\\{{v'_{t-n},\\cdots,v'_{t+n}}\\}\r\\\\\u0026=\\{\\mathrm{drop(v_{t-n}),\\cdots,\\mathrm{drop(v_{t+n})}}\\}\\in\\mathbb R^{(2n+1)\\times N'\\times(3P^2)}, \\quad N'\\lt N\r\\end{align}\r\\tag{2}\r$$Feature Extractionï¼šç‰¹å¾æå–éƒ¨åˆ†ï¼Œä½œè€…ç›´æ¥ä½¿ç”¨DINOv2è®­ç»ƒå¥½çš„VITæƒé‡æ¥è¿›è¡Œåˆå§‹åŒ–ï¼Œå¹¶å›ºå®šå‚æ•°ï¼š\n$$\\mathcal F=\\{\\mathrm{f_{t-n}, \\cdots, f_{t+n}\\}=\\bigg\\{\\phi_{DINO}(v'_{t-n}),\\cdots,\\phi_{DINO}(v'_{t+n})\\bigg\\}}\\in\\mathbb R^{(2n+1)\\times N'\\times D}\\tag{3} $$è¿™é‡Œ$ D $æ˜¯DINOv2æœ€åä¸€ä¸ªblockè¾“å‡ºç‰¹å¾çš„ç»´åº¦ï¼Œåœ¨æœ€åä¸€ä¸ªLayer Normalizationä¹‹å‰ã€‚ä½œè€…è¿™æ ·è®¾è®¡æœ‰ä¸¤ç‚¹åŸå› ï¼š\nmasked autoencodingåœ¨NLPå’ŒCVä»»åŠ¡ä¸­ï¼Œé€šå¸¸ä½œä¸ºè‡ªç›‘ç£å­¦ä¹ çš„ä»£ç†ä»»åŠ¡ï¼Œå€ŸåŠ©ä½œè€…çš„token dropæ¥å¼ºè¿«æ¨¡å‹è·å–é«˜è´¨é‡çš„è§†è§‰è¡¨å¾ å¯¹è§†é¢‘æ•°ç†æ¥è¯´ï¼Œé¢å¤–çš„æ—¶åºè½´å¼•å…¥äº†å‡ ä¸ªæ•°é‡çº§çš„æ•°æ®ï¼Œå¤„ç†é‡‡æ ·åçš„ç¨€ç–è§†è§‰tokenså¯ä»¥æå¤§åœ°å‡å°‘å†…å­˜é¢„ç®—ï¼Œä½œè€…åé¢æœ‰è¿›è¡ŒéªŒè¯ Spatial-temporal Binding ä»æ¯å¸§æå–åˆ°è§†è§‰ç‰¹å¾åï¼Œé¦–å…ˆåœ¨ç©ºé—´ä¸Šå°†å›¾åƒåŒºåŸŸåˆ†ç»„åˆ°slotsä¸­ï¼Œæ¯ä¸ªslotæŒ‡å®šä¸€ä¸ªè¯­ä¹‰å¯¹è±¡ï¼Œ å³åœ¨å•å¼ å›¾åƒä¸­å‘ç°å¯¹è±¡çš„è¿‡ç¨‹ï¼›ç„¶åç”¨Transformeråœ¨slotsä¸­å»ºç«‹temporal bindingï¼Œä¹Ÿå°±æ˜¯å…³è”è§†é¢‘ç‰‡æ®µä¸­çš„å¯¹è±¡ã€‚\n$$\r\\Phi_{\\mathrm{st-bind}}(\\mathcal F)=\\psi_{\\mathrm{t-bind}}\\big(\\psi_{\\mathrm{s-bind}}(\\bold f_{t-n}),\\cdots,\\psi_{\\mathrm{s-bind}}(\\bold f_{t+n})\\big)\\in\\mathbb R^{K\\times D_{\\rm slot}}\\tag{4}\r$$Spatial Binding ($ \\psi_{\\bold{s-bind}} $)ï¼šSpatial bindingè¿‡ç¨‹ç‹¬ç«‹ä½œç”¨äºå„å¸§ã€‚ä½œè€…ä½¿ç”¨Bizaæå‡ºçš„invariant slot attentionï¼Œæœ‰ä¸€ç‚¹ä¸åŒï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥$ \\mathcal T\\in\\{t-n,\\cdots,t+n\\} $ä½¿ç”¨ä¸€ä¸ªå…±äº«çš„åˆå§‹åŒ–$ \\mathcal {Z_T} $ã€‚\nå…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªæ—¶é—´æ­¥$ \\mathcal T $çš„ç‰¹å¾ç»è¿‡token dropä¹‹åä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬å­¦ä¹ ä¸€ç»„åˆå§‹åŒ–çš„å‘é‡ï¼Œç”¨$ K $ä¸ªslotå‘é‡$ \\bold z^j\\in\\mathbb R^{D_{\\rm slot}} $ã€$ K $ä¸ªç¼©æ”¾å‘é‡$ \\bold S^j_s\\in\\mathbb R^2 $ã€$ K $ä¸ªä½ç½®å‘é‡$ \\bold S^j_p\\in\\mathbb R^2 $ä»¥åŠä¸€ä¸ªç»å¯¹ä½ç½®åµŒå…¥grid$ \\bold G_{abs}\\in\\mathbb R^{N\\times 2} $åˆ†åˆ«å¹³ç§»å’Œç¼©æ”¾æ¯ä¸ªslotçš„è¾“å…¥ä½ç½®ç¼–ç ã€‚\nä½œè€…å°†ç‰¹å¾ç¼–ç ä¸­è¢«ä¸¢å¼ƒçš„tokenså¯¹åº”çš„patchesé®ä½ï¼Œå¯¹æ¯å¸§$ \\tau $å¾—åˆ°ä¸€ä¸ªç»å¯¹ä½ç½®åµŒå…¥$ \\bold G_{abs}=\\rm drop(\\bold G_{abs})\\in\\mathbb R^{N'\\times 2} $ã€‚å¯¹æ¯å¸§å›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸‹é¢çš„ä¸€ç»„å¯å­¦ä¹ å‘é‡ï¼š\n$$\r\\mathcal Z_\\tau=\\bigg\\{(\\bold z^j,\\bold S^j_s,\\bold S^j_p,\\bold G_{abs,\\tau})\\bigg\\}^K_{j=1}\\tag{5}\r$$è¿™é‡Œè¿™äº›å¯å­¦ä¹ çš„å‚æ•°æ˜¯å¯¹æ‰€æœ‰å¸§å…±äº«çš„ï¼Œä¸”æ ¹æ®å¯¹åº”å¸§çš„å¯†é›†è§†è§‰ç‰¹å¾è¿›è¡Œæ›´æ–°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸åŒå¸§çš„slotsåˆšå¼€å§‹æ˜¯ç›¸åŒçš„è¡¨å¾ï¼Œç»è¿‡bindæ“ä½œä¹‹åç”±äºæœ‰å’Œå¸§å†…ç‰¹å¾çš„äº¤äº’è€Œä¸åŒã€‚æœ¬è´¨ä¸Šæ¥è¯´ï¼Œè¿ç»­çš„å¸§é€šå¸¸å…·æœ‰ç›¸ä¼¼çš„è§†è§‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå› æ­¤ä½¿ç”¨å­¦ä¹ åˆ°çš„slotsè‡ªç„¶åœ°ä¼šä¿ƒè¿›temporal bindingï¼Œå³å…·æœ‰ç›¸åŒç´¢å¼•çš„slotsèƒ½å¤Ÿè·¨å¸§ç»‘å®šåˆ°ç›¸åŒçš„å¯¹è±¡åŒºåŸŸã€‚\nInvariant slot attentionç»†èŠ‚è§åŸæ–‡ï¼Œç²—ç•¥çœ‹ä¸‹æ¥æ˜¯åˆ©ç”¨ä½ç½®ç¼–ç æ¥å­¦ä¹ å…³ç³»ã€‚\nTemporal Binding ($ \\psi_{\\bold{t-bind}} $): åˆ°è¿™é‡Œä¸ºæ­¢ï¼Œæ¨¡å‹åªèƒ½é€šè¿‡åˆ©ç”¨æ¥è‡ªå•ä¸ªå¸§çš„ä¿¡æ¯æ¥å‘ç°å¯¹è±¡ã€‚æœ¬èŠ‚çš„ç›®çš„æ˜¯å€ŸåŠ©æ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å¢å¼ºslotè¡¨å¾ã€‚ç»™å®šä¸€ä¸ªæ¥è‡ªspatial bindingæ¨¡å—çš„è¾“å‡ºslots$ \\bigg\\{\\{\\bold{z}^j_{t-n}\\}^K_{j=1},â€¦,\\{\\bold{z}^j_{t+n}\\}^K_{j=1}\\bigg\\}\\in\\mathbb R^{(2n+1)\\times K\\times D_{\\rm slot}} $ï¼Œä½œè€…ç›´æ¥ä½¿ç”¨Transformerç¼–ç å™¨æ¥å¤„ç†è·¨ä¸åŒå¸§ä¸”å…·æœ‰ç›¸åŒç´¢å¼•çš„è¾“å‡ºslotsï¼Œè¿™é‡Œè‡ªæ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ çš„æ˜¯ä¸€ä¸ªè·¨$ (2n+1) $ä¸ªæ—¶é—´æ­¥çš„$ (2n+1)\\times(2n+1) $affinityçŸ©é˜µã€‚å€ŸåŠ©è‡ªæ³¨æ„åŠ›ï¼ŒTransformerå¯ä»¥å­¦ä¹ æ¯ä¸ªslotè¿‡å»ã€ç°åœ¨ã€æœªæ¥çš„æ—¶é—´æ­¥é‡Œçš„è¡¨å¾ï¼Œå€Ÿæ­¤ç”Ÿæˆæ›´robustè¡¨å¾ã€‚ä¸ºäº†åŒºåˆ†ä¸åŒæ—¶é—´æ­¥ï¼Œä½œè€…å°†å¯å­¦ä¹ çš„æ—¶é—´ä½ç½®ç¼–ç æ·»åŠ åˆ°slotsä¸­ï¼Œç›¸åŒå¸§å†…çš„slotsä½¿ç”¨ç›¸åŒçš„ç¼–ç ã€‚è¯¥temporal transformeræœ€ç»ˆå¾—åˆ°ç›®æ ‡æ—¶é—´æ­¥$ t $æ›´æ–°åçš„slots$ \\bold c $ä¸ºï¼š $$ \\bold c=\\Phi_{\\mathrm{st-bind}}(\\mathcal F)\\in\\mathbb R^{K\\times D_{\\rm slot}}\\tag{6} $$Visual Decoder å‰é¢çš„spatial-temporal bindingè¿‡ç¨‹å¾—åˆ°åœ¨æ—¶é—´æ­¥$ t $çš„ä¸€ç»„slotå‘é‡$ \\bold c\\in\\mathbb R^{K\\times D_{\\rm slot}} $ã€‚ä½†æ˜¯ï¼ŒçœŸå®çš„è§†é¢‘ä¸­ï¼Œå•ä¸ªå¸§å†…çš„å¯¹è±¡çš„æ•°é‡å¯èƒ½å˜åŒ–å¾ˆå¤§ï¼Œå› æ­¤å¦‚æœä½¿ç”¨å›ºå®šæ•°é‡çš„slotså¯èƒ½ä¼šå¯¼è‡´è¿‡åº¦èšç±»ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªå›°éš¾ï¼Œä½œè€…å€ŸåŠ©Agglomerative Clusteringç®—æ³•ï¼ˆå±‚æ¬¡èšç±»ï¼‰æå‡ºä¸€ä¸ªç”¨äºslotèåˆçš„ç®€å•è§£å†³æ–¹æ¡ˆã€‚æ­¤å¤–è¿˜æœ‰ä¸€ä¸ªé‡å»ºè§†é¢‘ç‰¹å¾çš„slotè§£ç æ­¥éª¤ï¼Œå’Œç‰¹å¾ç©ºé—´ä¸­çš„MAEç±»ä¼¼ã€‚\n$$ \\Phi_{\\mathrm{vis-dec}}(\\bold c)=\\psi_{\\rm dec}\\circ\\psi_{\\rm merge}(\\bold c)\\tag{7} $$\rSOLVæ•´ä½“ç»“æ„åŠå·¥ä½œæµç¨‹\rSlot Merging ($ \\psi_{\\bold{merge}} $): è‡ªç›‘ç£è®¾å®šä¸‹ï¼Œå¯¹è±¡çš„åˆ†å‰²é—®é¢˜é€šå¸¸æ˜¯ä¸€ä¸ªéš¾ä»¥ç•Œå®šçš„é—®é¢˜ï¼Œå› ä¸ºä¸€ä¸ªè§†è§‰åŒºåŸŸå¯ä»¥æœ‰å¤šä¸ªè§£é‡Šã€‚æ¯”å¦‚å›¾åƒä¸­çš„ä¸€ä¸ªäººï¼Œå¸¸è§çš„åšæ³•æ˜¯å°†è¿™ä¸ªäººå æ®çš„æ‰€æœ‰åƒç´ éƒ½åˆ†ä¸ºä¸€ç»„ï¼Œæˆ–è€…å°†è¿™ä¸ªâ€œäººâ€åˆ†è§£ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼šè„¸ã€æ‰‹è‡‚ã€èº«ä½“å’Œè…¿ç­‰ç»„ã€‚ç„¶é¹…ï¼Œç»éªŒä¸Šæ¥è¯´ï¼Œæ¥è‡ªåŒä¸€å¯¹è±¡çš„åƒç´ embeddingså¯¹æ¯”æ¥è‡ªä¸åŒå¯¹è±¡çš„åƒç´ embeddingsï¼Œæ¥è‡ªåŒä¸€å¯¹è±¡çš„åº”å½“æ›´ç›¸è¿‘ã€‚ä½œè€…ä½¿ç”¨Agglomerative Clusteringï¼ˆå±‚æ¬¡èšç±»ç®—æ³•ï¼‰æ¥èåˆslotsï¼Œä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦‚ä¸Šå›¾ï¼Œå…ˆåŸºäºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—æ‰€æœ‰slotsçš„affinityçŸ©é˜µï¼Œç„¶ååˆ©ç”¨è¿™ä¸ªçŸ©é˜µå°†æ‰€æœ‰çš„slotsè¿›è¡Œèšç±»åˆ†ç»„ï¼Œæ¥ç€ä¸ºæ¯ä¸ªç°‡è®¡ç®—å¹³å‡slotï¼š $$ \\bold c'=\\psi_{\\rm merge}(\\bold c)\\in\\mathbb R^{K_r\\times D_{\\rm slot}}, \\qquad K_t\\le K\\tag{8} $$\ré€šè¿‡èåˆå¯¹åº”äºåŒä¸€å¯¹è±¡çš„è¯­ä¹‰ä¸Šç›¸ä¼¼çš„slotsï¼Œæˆ‘ä»¬å°±å¯ä»¥åŠ¨æ€åœ°ç¡®å®šslotsçš„æœ€ä¼˜æ•°é‡ï¼ˆğŸ¤”not goodï¼‰ã€‚è¯¥slotèåˆæ­¥éª¤å¹¶ä¸æ˜¯ä¸€ä¸ªåå¤„ç†æ­¥éª¤ï¼Œè€Œæ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­å¿…ä¸å¯å°‘çš„ä¸€éƒ¨åˆ†ï¼Œæ¯•ç«Ÿè¿™æ ·çš„èšç±»å¾—åˆ°çš„ç‰¹å¾æ›´åŠ ç‹¬ç‰¹ï¼Œèƒ½å¸®åŠ©ç½‘ç»œå­¦ä¹ å¯¹è±¡çš„è¡¨å¾ã€‚ä¸‹å›¾ï¼ˆå·¦ï¼‰æ˜¯ä¸ä½¿ç”¨è¯¥slotèåˆï¼Œå›¾ï¼ˆå³ï¼‰æ˜¯ä½¿ç”¨è¯¥slotèåˆæ­¥éª¤çš„ç»“æœå¯è§†åŒ–ï¼š\nDecoder ($ \\psi_{\\bold{dec}} $): ä½¿ç”¨è§£ç å™¨æ¥å°†èåˆå¾—åˆ°çš„slots$ \\bold c' $è§£ç å¾—åˆ°å¯¹åº”çš„åˆ†å‰²æ©ç $ \\bold m $ä»¥åŠå®Œæ•´çš„é‡å»ºä¿¡å·$ \\bold y $ï¼š\n$$ \\bold y, \\bold m = \\psi_{\\rm dec}(\\bold c'),\\quad \\bold y\\in\\mathbb R^{N\\times D},\\bold m \\in \\mathbb R^{K_t\\times N}\\tag{9} $$ä½œè€…ä½¿ç”¨reshapeå’Œupsampleæ¥å¤„ç†å¾—åˆ°çš„æ©ç $ \\bold m $ä»¥æ¢å¤åŸå§‹è¾“å…¥å°ºå¯¸å¾—åˆ°æœ€ç»ˆçš„åˆ†å‰²è¾“å‡ºã€‚å’ŒDINOSAURè¿™ç¯‡è®ºæ–‡çš„MLPè§£ç å™¨ç±»ä¼¼ï¼Œä½œè€…ä½¿ç”¨ä¸€ä¸ªspatial broadcastè§£ç å™¨æ¥ä¸ºæ¯ä¸ªslot$ j $é‡å»ºå®Œæ•´çš„ç‰¹å¾å›¾$ \\hat{\\bold y}\\in\\mathbb R^{N\\times D} $ï¼Œå®ƒä»¬çš„alphaæƒé‡$ \\alpha^j\\in\\mathbb R^N $ã€‚å¯¹è¿™ä¸ªæƒé‡ä½¿ç”¨softmaxå‡½æ•°ä»¥å¾—åˆ°æœ€ç»ˆçš„åˆ†å‰²æ©ç ã€‚è§£ç é˜¶æ®µæ·»åŠ äº†å­¦ä¹ åˆ°çš„ä½ç½®ç¼–ç ã€‚å¯¹æ¯ä¸ªslot$ \\bold c'^j $ï¼Œå°†å®ƒçš„å½¢çŠ¶broadcastè‡³è¾“å…¥çš„ç‰¹å¾å›¾çš„å½¢çŠ¶ï¼Œç„¶åä½¿ç”¨ä¸€ç³»åˆ—çº¿æ€§å±‚$ \\psi_{\\rm mapper} $è¿›è¡Œè§£ç ï¼Œè¿™äº›å±‚åœ¨æ‰€æœ‰slotsä¸­æƒé‡å…±äº«ã€‚æœ€ç»ˆçš„é‡å»ºç‰¹å¾ç”±è§£ç åçš„slotsåŠ æƒæ±‚å’Œå¾—åˆ°ï¼š\n$$\r\\bold y=\\sum_{j=1}^{K_t}\\hat{\\bold y}^j\\odot\\bold m^j,\\qquad \\bold m^j=\\mathrm{softmax}(\\boldsymbol\\alpha^j),\\\\ \\boldsymbol\\alpha^j,\\hat{\\bold{y}}^j=\\psi_{\\rm mapper}\\bigg(\\mathrm{broadcast}\\Big(\\bold c'^j\\Big)\\bigg)\r\\tag{10}\r$$è®­ç»ƒä¸­ï¼Œä½œè€…é€šè¿‡æœ€å°åŒ–åœ¨æ—¶é—´æ­¥$ t $å¾—åˆ°çš„æœªè¿›è¡Œé®ç›–çš„å¸§å›¾åƒï¼Œç»è¿‡DINOè¿›è¡Œç¼–ç å¾—åˆ°çš„ç‰¹å¾å›¾ä¸­çš„tokenså’Œé‡å»ºåçš„tokens$~\\bold y $çš„å·®å¼‚æ¥ä¼˜åŒ–æ¨¡å‹ï¼š$ \\mathcal L=\\| \\phi_{\\mathrm{DINO}}(\\bold v_t)-\\bold y\\|^2 $\nç»“è®º ç»™å‡ºäº†ä¸€ä¸ªå¤§è‡´çš„æ¡†æ¶ï¼Œå¯ä»¥çœ‹åˆ°æœ€è¿‘çš„ç ”ç©¶å¤§å¤šæ•°æ˜¯è¿™ç±»â€”â€”é‡æ–°å®šä¹‰ä»»åŠ¡ï¼Œæ•´åˆç°æœ‰ç®—æ³•åŠæ•°æ®è§£å†³æ–°ä»»åŠ¡ã€‚åå­—èµ·çš„å¾ˆå“äº®ï¼Œå¯æƒœå®é™…çš„è§£å†³æ–¹æ¡ˆè¿˜æ˜¯æœªçªç ´è‡ªç›‘ç£å­¦ä¹ çš„èŒƒå¼ï¼Œä»£ç†ä»»åŠ¡è¿˜æ˜¯ä¹‹å‰çš„æ–¹æ¡ˆã€‚\n","permalink":"https://milknocandy.github.io/posts/2023-12-10-cutler/","summary":"\u003cblockquote\u003e\n\u003cp\u003eæ¥æºï¼š\u003ca href=\"https://openreview.net/group?id=NeurIPS.cc/2023/Conference\"\u003eNIPS 2023\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eè®ºæ–‡åœ°å€ï¼š\u003ca href=\"http://arxiv.org/abs/2310.06907\"\u003ehttp://arxiv.org/abs/2310.06907\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eä»£ç åœ°å€ï¼šâŒ\u003c/p\u003e\n\u003cp\u003eä½œè€…ä¸»é¡µï¼šäºŒä½œè°¢ä¼Ÿè¿ªä¸»é¡µ\u003ca href=\"https://weidixie.github.io/\"\u003ehttps://weidixie.github.io/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eé¡¹ç›®ä¸»é¡µï¼š\u003ca href=\"https://kuis-ai.github.io/solv/\"\u003ehttps://kuis-ai.github.io/solv/\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"ä»‹ç»\"\u003eä»‹ç»\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eèƒŒæ™¯\u003c/strong\u003eï¼š\u003cu\u003eæ— ç›‘ç£å¤šç›®æ ‡åˆ†å‰²\u003c/u\u003eå€ŸåŠ©è‡ªç›‘ç£å­¦ä¹ é¢„è®­ç»ƒä¸­å­¦ä¹ åˆ°çš„å¼ºåŠ›çš„è¯­ä¹‰ä¿¡æ¯å±•ç¤ºäº†æ˜¾è‘—çš„æ•ˆæœã€‚é€šå¸¸ä¹Ÿæ˜¯é€šè¿‡æ·»åŠ é¢å¤–çš„æ¨¡æ€ï¼ˆæ¯”å¦‚æ·±åº¦ã€åŠ¨ä½œï¼‰æ¥å¢å¼ºè§†é¢‘åºåˆ—çš„åˆ†å‰²ç»“æœã€‚ç„¶è€Œï¼Œåœ¨ _åˆæˆåºåˆ— _ä¸­è§‚å¯Ÿåˆ°çš„æ€§èƒ½æå‡\u003cu\u003eä¾èµ–\u003c/u\u003eäºé¢å¤–ä¿¡æ¯çš„é²æ£’æ€§ï¼Œå¹¶ä¸èƒ½è½¬åŒ–ä¸ºæ›´å…·æŒ‘æˆ˜çš„çœŸå®ä¸–ç•Œåœºæ™¯ã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eä»»åŠ¡\u003c/strong\u003eï¼šç»™å®šä¸€ä¸ªå¤æ‚åœºæ™¯çš„è§†é¢‘åºåˆ—ï¼Œç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªè§†è§‰ç³»ç»Ÿèƒ½å¤Ÿ\u003cu\u003eå‘ç°ã€è¿½è¸ªå’Œåˆ†å‰²\u003c/u\u003eå›¾åƒå¸§é‡Œçš„ç›®æ ‡ï¼Œå°†æ•°ç™¾ä¸‡çš„åƒç´ çš„è§†è§‰ä¿¡æ¯æŠ½è±¡ä¸º\u003ci\u003eè¯­ä¹‰éƒ¨åˆ†\u003c/i\u003eã€‚ï¼ˆobject-centricè§†è§‰è¡¨å¾å­¦ä¹ ï¼‰\u003c/p\u003e\n\u003cfigure class=\"main-figure\"\u003e\r\n  \u003cdiv class=\"side-by-side-wrapper grid-layout\"\u003e\r\n    \u003cdiv class=\"side-item\" style=\"--w: 45%\"\u003e\r\n      \u003cimg src=\"1.gif\"\u003e\r\n      \u003cp\u003e(a) Ground Truth\u003c/p\u003e\r\n    \u003c/div\u003e\r\n    \u003cdiv class=\"side-item\" style=\"--w: 45%\"\u003e\r\n      \u003cimg src=\"1-2.gif\"\u003e\r\n      \u003cp\u003e(b) Prediction\u003c/p\u003e\r\n    \u003c/div\u003e\r\n  \u003c/div\u003e\r\n  \u003c!-- \u003cfigcaption\u003e\r\n    \u003cspan class=\"auto-fig-title\"\u003eéå¯¹ç§°æ¯”ä¾‹å¯¹æ¯”\u003c/span\u003e\r\n  \u003c/figcaption\u003e --\u003e\r\n\u003c/figure\u003e\r\n\u003cp\u003e\u003cstrong\u003eé¢†åŸŸçš„å‘å±•\u003c/strong\u003eï¼šä»\u003ci\u003eåˆæˆå›¾åƒ\u003c/i\u003eå¼€å§‹ï¼Œè½¬å‘\u003cu\u003ein-the-wild\u003c/u\u003eå›¾åƒå’Œ\u003cu\u003ereal-world\u003c/u\u003eè§†é¢‘ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨è‡ªç¼–ç å™¨è®­ç»ƒèŒƒå¼ï¼ˆå¦‚é‡å»ºè¾“å…¥ä¿¡å·ï¼Œå¸Œæœ›èƒ½åŸºäºæ•°æ®æˆ–ç»“æ„çš„å…ˆéªŒæ¥å°†\u003cu\u003eåŒºåŸŸåƒç´ \u003c/u\u003eåˆ†ç»„ä¸ºæœ‰è¯­ä¹‰æ„ä¹‰çš„å¯¹è±¡ï¼‰ã€‚\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eå¯¹å›¾åƒï¼šä½¿ç”¨æ¥æºäºé¢„è®­ç»ƒæ¨¡å‹çš„\u003cu\u003eä½çº§ç‰¹å¾\u003c/u\u003eï¼ˆå¦‚é¢œè‰²ã€è¯­ä¹‰ç‰¹å¾ç­‰ï¼‰æ¥ç¡®å®šåƒç´ åˆ°ç›®æ ‡çš„åˆ†é…\u003c/li\u003e\n\u003cli\u003eå¯¹è§†é¢‘ï¼šé€šå¸¸ç»“åˆé¢å¤–çš„æ¨¡æ€ã€ä¿¡å·ï¼ˆå¦‚å…‰æµã€æ·±åº¦å›¾ï¼‰ï¼Œå¯ç›´æ¥ä»ä¸è¿ç»­æ€§è·å¾—åˆ†å‰²æ©ç \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"æå‡ºé—®é¢˜\"\u003eæå‡ºé—®é¢˜\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eä½¿ç”¨é¢å¤–ä¿¡æ¯å¸¦æ¥çš„é—®é¢˜\u003c/strong\u003eï¼šåœ¨è§†é¢‘ä¸­ä½¿ç”¨é¢å¤–çš„ä¿¡å·ä¼šå¢åŠ \u003cstrong\u003eè®¡ç®—å¼€é”€\u003c/strong\u003eå’Œ\u003cstrong\u003eè¯¯å·®ç´¯ç§¯\u003c/strong\u003eã€‚æ¯”å¦‚å…‰æµä¿¡å·åœ¨å¤„ç†\u003cu\u003eé™æ€æˆ–å¯å˜å½¢\u003c/u\u003eç‰©ä½“ä»¥åŠå¸§é—´\u003cu\u003eå¤§ä½ç§»\u003c/u\u003eæ—¶å¯èƒ½ä¼šäº§ç”Ÿé—®é¢˜ï¼Œè€Œæ·±åº¦å€¼åœ¨æ™®é€šè§†é¢‘ä¸­å¯èƒ½ä¸æ˜“è·å¾—ï¼Œåœ¨\u003cu\u003eä½å…‰ç…§\u003c/u\u003eæˆ–\u003cu\u003eä½å¯¹æ¯”åº¦\u003c/u\u003eç¯å¢ƒä¸­å…¶ä¼°ç®—ä¹Ÿä¼šå—åˆ°å½±å“ã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eè¿‡åº¦åˆ†å‰²é—®é¢˜\u003c/strong\u003eï¼šç”±äºè§†è§‰åœºæ™¯çš„å¤æ‚æ€§ï¼Œä½¿ç”¨å›ºå®šæ•°é‡çš„\u003cu\u003eslots\u003c/u\u003eå¯èƒ½å¯¼è‡´è¿‡åº¦åˆ†å‰²é—®é¢˜ï¼ˆover-segmentation issuseï¼‰ã€‚\u003c/p\u003e\n\u003ch3 id=\"è§£å†³é—®é¢˜\"\u003eè§£å†³é—®é¢˜\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eä½œè€…æ–¹æ³•\u003c/strong\u003eï¼š\u003cstrong\u003eé¦–æ¬¡\u003c/strong\u003eæå‡ºç”¨äº\u003cu\u003eçœŸå®ä¸–ç•Œåºåˆ—ä¸­å¤šç›®æ ‡åˆ†å‰²\u003c/u\u003eçš„å®Œå…¨æ— ç›‘ç£æ–¹æ³•ã€‚SOLVï¼Œä¸€ä¸ªèƒ½å¤Ÿå‘ç°çœŸå®ä¸–ç•Œè§†é¢‘åºåˆ—ä¸­å¤šä¸ªç›®æ ‡ä¸”ä¸ä½¿ç”¨é¢å¤–çš„æ¨¡æ€ä¿¡æ¯æˆ–ä»»ä½•ç±»ä¼¼å¼±ç›‘ç£æ–¹æ³•ï¼ˆæ¯”å¦‚ä½¿ç”¨ç¬¬ä¸€å¸§è¿›è¡Œåˆå§‹åŒ–ï¼‰ã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eæ–¹æ¡ˆ\u003c/strong\u003eï¼šä½¿ç”¨è½´å‘ç©ºé—´-æ—¶éš™æ³¨æ„åŠ›ï¼ˆaxial spatial-temporal slot attentionsï¼‰\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eé¦–å…ˆå¯¹æ¯å¸§å†…ç©ºé—´åŒºåŸŸè¿›è¡Œåˆ†ç»„\u003c/li\u003e\n\u003cli\u003eç„¶åä½¿ç”¨æ¥è‡ªç›¸é‚»å¸§çš„äº¤äº’æ¥ä¸°å¯Œæ—¶éš™è¡¨ç¤ºï¼ˆslot representationsï¼‰\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eè®­ç»ƒç­–ç•¥\u003c/strong\u003eï¼šmasked autoencoderï¼ˆMAEï¼‰è®­ç»ƒèŒƒå¼ã€‚ä¸¤ä¸ªä¼˜åŠ¿ï¼š\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eå……å½“ä¿¡æ¯ç“¶é¢ˆï¼ˆinformation bottleneckï¼‰ï¼Œè®©æ¨¡å‹è§‚å¯Ÿéƒ¨åˆ†åŒºåŸŸï¼Œå¼ºè¿«æ¨¡å‹å­¦ä¹ é«˜çº§è¯­ä¹‰ç»“æ„ã€‚\u003c/li\u003e\n\u003cli\u003eç¼“è§£å†…å­˜é™åˆ¶ï¼Œæœ‰åŠ©äºæé«˜è®¡ç®—æ•ˆç‡\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eé’ˆå¯¹\u003cstrong\u003eover-segmentation\u003c/strong\u003eé—®é¢˜ï¼šä½œè€…é€šè¿‡ä½¿ç”¨ç®€å•çš„èšç±»ç®—æ³•æ¥èåˆç›¸ä¼¼çš„slotsã€‚\u003c/p\u003e\n\u003cp\u003eæ€»çš„æ¥è¯´ï¼Œè´¡çŒ®å¦‚ä¸‹ï¼š\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eæå‡ºä¸€ä¸ªåœ¨çœŸå®ä¸–ç•Œè§†é¢‘ä¸Šçš„è‡ªç›‘ç£å¤šç›®æ ‡åˆ†å‰²æ¨¡å‹ï¼Œä½¿ç”¨axial spatial-temporal slots attentionï¼Œèƒ½æœ‰æ•ˆåœ°å°†å…·æœ‰ç›¸ä¼¼ç‰¹æ€§çš„è§†è§‰åŒºåŸŸè¿›è¡Œåˆ†ç»„ï¼Œè€Œä¸éœ€è¦ä½¿ç”¨\u003cu\u003eé¢å¤–çš„ä¿¡å·\u003c/u\u003eã€‚\u003c/li\u003e\n\u003cli\u003eå±•ç¤ºäº†ä¸€ä¸ªåŸºäºæ©ç ç‰¹å¾é‡å»ºçš„object-centricå­¦ä¹ æ–¹å¼ä»¥åŠslotèåˆæ–¹æ³•ã€‚\u003c/li\u003e\n\u003cli\u003eMOVi-Eå’ŒYoutube-VIS 2019æ•°æ®é›†ä¸Šçš„SOTAä»¥åŠDAVIS2017æ•°æ®é›†ä¸Šçš„å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eslotå³è§†é¢‘ä¸­çš„å„ç‰©ä½“å¯¹è±¡ï¼Œè§ä¸‹å›¾ã€‚\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\r\n\u003cfigure \u003e\r\n    \u003cimg src=\"2.png\" alt=\"Source from: Conditional object-centric learning from video\" /\u003e\u003cfigcaption\u003e\r\n        \u003cspan class=\"auto-fig-title\"\u003eSource from: Conditional object-centric learning from video\u003c/span\u003e\r\n    \u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\u003ch3 id=\"ç›¸å…³å·¥ä½œ\"\u003eç›¸å…³å·¥ä½œ\u003c/h3\u003e\n\u003ch4 id=\"object-centric-learning\"\u003eObject-centric Learning\u003c/h4\u003e\n\u003cp\u003eå›¾åƒå’Œè§†é¢‘çš„object-centricæ— ç›‘ç£è¡¨å¾å­¦ä¹ ç°æœ‰å‡ ç§è§£å†³åŠæ³•ï¼š\u003c/p\u003e","title":"Self-supervised Object-Centric Learning for Videos"}]